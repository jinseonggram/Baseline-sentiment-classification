{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TH32rzgprvgM"
      },
      "source": [
        "# Import requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9EvC1HBuf41",
        "outputId": "91f589b0-5ac5-4b2f-d76c-83e6ae5ab8aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 14.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: Sentencepiece\n",
            "Successfully installed Sentencepiece-0.1.97\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.22.2-py3-none-any.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 15.1 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.9.0\n",
            "  Downloading huggingface_hub-0.10.0-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 55.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 33.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.10.0 tokenizers-0.12.1 transformers-4.22.2\n"
          ]
        }
      ],
      "source": [
        "!pip install Sentencepiece\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JRggUsMelIGf",
        "outputId": "4b6fa6f9-b706-4358-bd7c-f4bb816d01eb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.13.3-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 15.5 MB/s \n",
            "\u001b[?25hCollecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 88.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.9.9-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[K     |████████████████████████████████| 162 kB 49.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.9.8-py2.py3-none-any.whl (158 kB)\n",
            "\u001b[K     |████████████████████████████████| 158 kB 76.9 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.7-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 80.3 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.6-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 78.5 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.5-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 79.1 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.4-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 91.7 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.3-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 80.6 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.2-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 89.1 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.1-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 84.9 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n",
            "\u001b[K     |████████████████████████████████| 156 kB 81.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=1f1f917b268aee0b329283c88b2cbfe2fc25e84d570a5134a3086c09fc11caa0\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.9.0 setproctitle-1.3.2 shortuuid-1.0.9 smmap-5.0.0 wandb-0.13.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AAdLxrUZrvgP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pdb\n",
        "import argparse\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Optional\n",
        "from collections import defaultdict\n",
        "\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.optim as optim\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "from transformers import (\n",
        "    BertForSequenceClassification,\n",
        "    BertTokenizer,\n",
        "    AutoConfig,\n",
        "    AdamW,\n",
        "    \n",
        "    AlbertTokenizer, AlbertForSequenceClassification\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASWOOmXqrvgQ"
      },
      "source": [
        "# 1. Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RAnU6w29rvgR"
      },
      "outputs": [],
      "source": [
        "def make_id_file(task, tokenizer):\n",
        "    def make_data_strings(file_name):\n",
        "        data_strings = []\n",
        "        with open(os.path.join(file_name), 'r', encoding='utf-8') as f:\n",
        "            id_file_data = [tokenizer.encode(line.lower()) for line in f.readlines()]\n",
        "        for item in id_file_data:\n",
        "            data_strings.append(' '.join([str(k) for k in item]))\n",
        "        return data_strings\n",
        "    \n",
        "    print('it will take some times...')\n",
        "    train_pos = make_data_strings('sentiment.train.1')\n",
        "    train_neg = make_data_strings('sentiment.train.0')\n",
        "    dev_pos = make_data_strings('sentiment.dev.1')\n",
        "    dev_neg = make_data_strings('sentiment.dev.0')\n",
        "\n",
        "    print('make id file finished!')\n",
        "    return train_pos, train_neg, dev_pos, dev_neg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "62f2348e08eb40aeba7d33b66baf1ff3",
            "8738b98f152142d2a177f4ee50d8a6ff",
            "9548480e42904ff4832484dffe062d40",
            "762b596999174feaa588963c0345da90",
            "197e3e9cebfd40639c05e3afdc6e5a4c",
            "42e37e5d79f24e98a0465166d5a9ba0b",
            "4a01a2b91b104f4ea0da7627e8165955",
            "faf7049c768541bbaf1a89ad61b58bf7",
            "e517071f6eb1419fab44023518f478ab",
            "3183323db2e94e54b3f5763280bd2257",
            "18362cfce3a74dbcbe427f336ed5c378",
            "67360c7aaa1e4eb99aeaf0c58dfdc56f",
            "ae0b4eb347524a22976c56554cf17678",
            "2be4709a0fe9473f847b18d762e1a7e8",
            "a36e90ac65ad437885ee984cb5f23865",
            "0caff7507416409d9d19a755e4b8fcf2",
            "d0dd3a19a30848c2a2e983227ab38f05",
            "5ac57ca70c114341b5f4fb4a6b81055b",
            "9c17295c1c46481795d9eace888f4d38",
            "20c233796c16462caa5a2069adb0deda",
            "7b1600090f544a8e9ff64620215f3421",
            "de35c7639d474eafb793f6476d260b34"
          ]
        },
        "id": "Ui2HOCflrvgR",
        "outputId": "55063701-6964-4794-84ab-7d3ebf35a989"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/760k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62f2348e08eb40aeba7d33b66baf1ff3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/684 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67360c7aaa1e4eb99aeaf0c58dfdc56f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "tokenizer = AlbertTokenizer.from_pretrained(\"albert-base-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "4jVuK-V1uq3L",
        "outputId": "3c84369a-9d6d-41d3-acf5-93743cd27163"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-88b716bf-29a2-43e7-b331-b5e06e104527\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-88b716bf-29a2-43e7-b331-b5e06e104527\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving sentiment.train.0 to sentiment.train.0\n",
            "Saving sentiment.train.1 to sentiment.train.1\n",
            "Saving test_no_label.csv to test_no_label.csv\n",
            "Saving sentiment.dev.1 to sentiment.dev.1\n",
            "Saving sentiment.dev.0 to sentiment.dev.0\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttzRlY4Ov0jZ",
        "outputId": "e75882e0-28c4-4b2c-ebe0-a55d547b87fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: ls3: command not found\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAgztXIBrvgS",
        "outputId": "9a8c2c74-25f4-4b79-d830-3bbeba5412e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "it will take some times...\n",
            "make id file finished!\n"
          ]
        }
      ],
      "source": [
        "train_pos, train_neg, dev_pos, dev_neg = make_id_file('yelp', tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRh2WjGRrvgS",
        "outputId": "623941c9-e584-41ec-bd5a-dc24ec3f0ea9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['2 5977 950 13 9 3',\n",
              " '2 18656 7705 365 13 9 3',\n",
              " '2 59 67 57 1954 621 18 17 1392 5262 56 25 510 254 13 9 3',\n",
              " '2 32 13 22 18 21 254 13865 69 20538 7298 13 9 3',\n",
              " '2 14 1138 25 4753 13 9 3',\n",
              " '2 254 748 950 13 9 3',\n",
              " '2 254 365 13 9 3',\n",
              " '2 11554 16 208 25 27269 17 7503 16 621 18 13 9 3',\n",
              " '2 374 209 26 4311 54 748 16385 18 17 3911 13 9 3',\n",
              " '2 14 78 978 1879 5289 13 9 3']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "train_pos[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JdpQQQMUrvgT"
      },
      "outputs": [],
      "source": [
        "class SentimentDataset(object):\n",
        "    def __init__(self, tokenizer, pos, neg):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = []\n",
        "        self.label = []\n",
        "\n",
        "        for pos_sent in pos:\n",
        "            self.data += [self._cast_to_int(pos_sent.strip().split())]\n",
        "            self.label += [[1]]\n",
        "            # print('pos_sent: ', self.label, pos_sent)\n",
        "        for neg_sent in neg:\n",
        "            self.data += [self._cast_to_int(neg_sent.strip().split())]\n",
        "            self.label += [[0]]\n",
        "\n",
        "    def _cast_to_int(self, sample):\n",
        "        return [int(word_id) for word_id in sample]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sample = self.data[index]\n",
        "        return np.array(sample), np.array(self.label[index])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wCz5ey8xrvgU"
      },
      "outputs": [],
      "source": [
        "train_dataset = SentimentDataset(tokenizer, train_pos, train_neg)\n",
        "dev_dataset = SentimentDataset(tokenizer, dev_pos, dev_neg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "UuvkMczvrvgU"
      },
      "outputs": [],
      "source": [
        "# for i, item in reversed(list(enumerate(train_dataset))):\n",
        "#     print(item)\n",
        "#     if i == 1:\n",
        "#         break\n",
        "\n",
        "# for i, item in enumerate(train_dataset):\n",
        "#     print(item)\n",
        "#     if i == 1:\n",
        "#         break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "B0wRUBYSrvgU"
      },
      "outputs": [],
      "source": [
        "# def collate_fn_style(samples):\n",
        "#     # print('samples : ',samples)\n",
        "#     input_ids, labels = zip(*samples)\n",
        "#     # print('inputs : ', input_ids)\n",
        "#     # print('labels : ', labels)\n",
        "\n",
        "#     # batch 사이즈중 가장 긴 문장의 길이 추출\n",
        "#     max_len = max(len(input_id) for input_id in input_ids)\n",
        "\n",
        "#     # 조금 더 잘 pad 를 하기 위해 문장 정리\n",
        "#     sorted_indices = np.argsort([len(input_id) for input_id in input_ids])[::-1]\n",
        "    \n",
        "#     # 위에 오류\n",
        "#     # sorted_indices = range(len(input_ids))\n",
        "\n",
        "#     # https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_sequence.html, 길이를 맞추기 위해 pad 를 해줌. 전체적인 dim 이 같아짐.\n",
        "#     input_ids = pad_sequence([torch.tensor(input_ids[index]) for index in sorted_indices],\n",
        "#                              batch_first=True)\n",
        "    \n",
        "#     # 불필요한 영역에는 attention 을 두지 않도록 attention mask 생성.\n",
        "#     attention_mask = torch.tensor(\n",
        "#         [[1] * len(input_ids[index]) + [0] * (max_len - len(input_ids[index])) for index in\n",
        "#          sorted_indices])\n",
        "\n",
        "#     # attention_mask = []\n",
        "#     # for seq in input_ids:\n",
        "#     #   seq_mask = [float(i>0) for i in seq]\n",
        "#     #   attention_mask.append(seq_mask)\n",
        "    \n",
        "#     # attention_mask = torch.tensor(attention_mask)\n",
        "      \n",
        "#     token_type_ids = torch.tensor([[0] * len(input_ids[index]) for index in sorted_indices])\n",
        "#     position_ids = torch.tensor([list(range(len(input_ids[index]))) for index  in sorted_indices])\n",
        "#     labels = torch.tensor(np.stack(labels, axis=0)[sorted_indices])\n",
        "\n",
        "#     return input_ids, attention_mask, token_type_ids, position_ids, labels\n",
        "\n",
        "\n",
        "def collate_fn_style(samples):\n",
        "    input_ids, labels = zip(*samples)\n",
        "    max_len = max(len(input_id) for input_id in input_ids)\n",
        "    # sorted_indices = np.argsort([len(input_id) for input_id in input_ids])[::-1] \n",
        "    sorted_indices = range(len(input_ids))\n",
        "\n",
        "    # https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_sequence.html,\n",
        "    # 길이를 맞추기 위해 pad 를 해줌. batch 마다 적용\n",
        "    input_ids = pad_sequence([torch.tensor(input_ids[index]) for index in sorted_indices],\n",
        "                             batch_first=True)\n",
        "    # attention_mask = torch.tensor(\n",
        "    #     [[1] * len(input_ids[index]) + [0] * (max_len - len(input_ids[index])) for index in\n",
        "    #      sorted_indices])\n",
        "\n",
        "    attention_mask = []\n",
        "    for seq in input_ids:\n",
        "      seq_mask = [float(i>0) for i in seq]\n",
        "      attention_mask.append(seq_mask)\n",
        "    attention_mask = torch.tensor(attention_mask)\n",
        "\n",
        "    token_type_ids = torch.tensor([[0] * len(input_ids[index]) for index in sorted_indices])\n",
        "    position_ids = torch.tensor([list(range(len(input_ids[index]))) for index in sorted_indices])\n",
        "    labels = torch.tensor(np.stack(labels, axis=0)[sorted_indices])\n",
        "    \n",
        "\n",
        "    return input_ids, attention_mask, token_type_ids, position_ids, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5saagig0rvgV"
      },
      "outputs": [],
      "source": [
        "train_batch_size=128 # 32-> 128\n",
        "eval_batch_size=256 # 64-> 256\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                           batch_size=train_batch_size,\n",
        "                                           shuffle=True, collate_fn=collate_fn_style,\n",
        "                                           pin_memory=True, num_workers=2)\n",
        "dev_loader = torch.utils.data.DataLoader(dev_dataset, batch_size=eval_batch_size,\n",
        "                                         shuffle=False, collate_fn=collate_fn_style,\n",
        "                                         num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9LCKfZPyXd3",
        "outputId": "fd85c312-db16-4de8-8af6-9a4afbe853cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tensor([[   2,   48,  209,  ...,    0,    0,    0],\n",
            "        [   2, 2170,   14,  ...,    0,    0,    0],\n",
            "        [   2,   13, 1373,  ...,    0,    0,    0],\n",
            "        ...,\n",
            "        [   2,   31, 1905,  ...,    0,    0,    0],\n",
            "        [   2, 1138,   23,  ...,    0,    0,    0],\n",
            "        [   2,  207,   13,  ...,    0,    0,    0]]), tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [1., 1., 1.,  ..., 0., 0., 0.]]), tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]]), tensor([[ 0,  1,  2,  ..., 19, 20, 21],\n",
            "        [ 0,  1,  2,  ..., 19, 20, 21],\n",
            "        [ 0,  1,  2,  ..., 19, 20, 21],\n",
            "        ...,\n",
            "        [ 0,  1,  2,  ..., 19, 20, 21],\n",
            "        [ 0,  1,  2,  ..., 19, 20, 21],\n",
            "        [ 0,  1,  2,  ..., 19, 20, 21]]), tensor([[1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [0]])]\n"
          ]
        }
      ],
      "source": [
        "# for idx, i in enumerate(train_loader):\n",
        "#     input_ids, attention_mask, token_type_ids, position_ids, labels = i\n",
        "#     print(i)\n",
        "#     if idx == 0:\n",
        "#       break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 895,
          "referenced_widgets": [
            "eb7a330500aa4abdbda219867697f11a",
            "3e06884a6b354150bf8d1dfd5b9ba87c",
            "6ce242e334cb414f88738a527fb49bae",
            "32127cf0faf845d2bb2a54dd988f2185",
            "345d45ea8c574103a16e8a3c2d4d367a",
            "de2f19d81061499a9563857db295f25f",
            "ddd8903a26004259a780f6dbce0fa78b",
            "1b66dae20e8c40e496c3824818a5ef32",
            "4712e13e380346e3ace5d7feb7e76e85",
            "0fb5222330304651940f693b516c5b02",
            "0bd153b0b8bb46f0ba4968d3ad8afd59"
          ]
        },
        "id": "zvFqCaCnrvgW",
        "outputId": "e6c3641a-79e9-452d-c3ff-f81c93a1c89c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/47.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb7a330500aa4abdbda219867697f11a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.LayerNorm.weight', 'predictions.bias', 'predictions.LayerNorm.bias', 'predictions.decoder.bias', 'predictions.decoder.weight', 'predictions.dense.weight', 'predictions.dense.bias']\n",
            "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlbertForSequenceClassification(\n",
              "  (albert): AlbertModel(\n",
              "    (embeddings): AlbertEmbeddings(\n",
              "      (word_embeddings): Embedding(30000, 128, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 128)\n",
              "      (token_type_embeddings): Embedding(2, 128)\n",
              "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0, inplace=False)\n",
              "    )\n",
              "    (encoder): AlbertTransformer(\n",
              "      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n",
              "      (albert_layer_groups): ModuleList(\n",
              "        (0): AlbertLayerGroup(\n",
              "          (albert_layers): ModuleList(\n",
              "            (0): AlbertLayer(\n",
              "              (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (attention): AlbertAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (attention_dropout): Dropout(p=0, inplace=False)\n",
              "                (output_dropout): Dropout(p=0, inplace=False)\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              )\n",
              "              (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (activation): NewGELUActivation()\n",
              "              (dropout): Dropout(p=0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (pooler_activation): Tanh()\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# random seed\n",
        "random_seed=33 # 42 -> 33\n",
        "np.random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = AlbertForSequenceClassification.from_pretrained('albert-base-v2')\n",
        "# model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# GPU 에 얹어주는 작업\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWwhmyMyrvgW",
        "outputId": "dc43bc8b-d2e7-41a4-962f-4cd1a19d21be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "model.train()\n",
        "learning_rate = 1e-5\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "MztU-L83rvgW"
      },
      "outputs": [],
      "source": [
        "def compute_acc(predictions, target_labels):\n",
        "    return (np.array(predictions) == np.array(target_labels)).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c1fe327b0fe74445b42a3a177e1125ec",
            "bd336e7c9c2748a1a86f06d99bc24bd4",
            "0fbaeef907ee4c2c953fdf4f59f03df1",
            "79b20f1c45a04c2194b1565aac065151",
            "d9485e1d43274d4581dcbfd30e081be6",
            "1b5302f2a5834ce39cd1ed901e517fc7",
            "d81c88bab31e438da5362cc780924b6d",
            "401fab58599a46a3bffac5fa2b0c0aa5"
          ]
        },
        "id": "DuZfvzpGrvgW",
        "outputId": "7651909d-541b-4edf-cc43-20f3495153e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjinseonggram\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221002_215408-1qx3bvrc</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/jinseonggram/uncategorized/runs/1qx3bvrc\" target=\"_blank\">visionary-galaxy-8</a></strong> to <a href=\"https://wandb.ai/jinseonggram/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  20%|█▉        | 692/3463 [02:01<07:42,  6.00batch/s, loss=0.0298]\n",
            "Eval:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   6%|▋         | 1/16 [00:00<00:03,  4.11it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 2/16 [00:00<00:02,  5.57it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 3/16 [00:00<00:02,  6.21it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 4/16 [00:00<00:01,  6.69it/s]\u001b[A\n",
            "Eval:  31%|███▏      | 5/16 [00:00<00:01,  6.93it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 6/16 [00:00<00:01,  7.06it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 7/16 [00:01<00:01,  7.29it/s]\u001b[A\n",
            "Eval:  50%|█████     | 8/16 [00:01<00:01,  7.44it/s]\u001b[A\n",
            "Eval:  56%|█████▋    | 9/16 [00:01<00:00,  7.49it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 10/16 [00:01<00:00,  7.00it/s]\u001b[A\n",
            "Eval:  69%|██████▉   | 11/16 [00:01<00:00,  7.10it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 12/16 [00:01<00:00,  7.16it/s]\u001b[A\n",
            "Eval:  81%|████████▏ | 13/16 [00:01<00:00,  7.20it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 14/16 [00:02<00:00,  6.79it/s]\u001b[A\n",
            "Eval:  94%|█████████▍| 15/16 [00:02<00:00,  6.96it/s]\u001b[A\n",
            "Epoch 0:  20%|██        | 693/3463 [02:04<42:04,  1.10batch/s, loss=0.0298]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.97175 , current loss is 0.08111376478336751 , lowest_valid_loss : 0.08111376478336751\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  40%|███▉      | 1384/3463 [04:02<05:41,  6.09batch/s, loss=0.0236]\n",
            "Eval:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   6%|▋         | 1/16 [00:00<00:03,  4.42it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 2/16 [00:00<00:02,  5.80it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 3/16 [00:00<00:02,  6.39it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 4/16 [00:00<00:01,  6.82it/s]\u001b[A\n",
            "Eval:  31%|███▏      | 5/16 [00:00<00:01,  7.02it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 6/16 [00:00<00:01,  7.09it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 7/16 [00:01<00:01,  7.30it/s]\u001b[A\n",
            "Eval:  50%|█████     | 8/16 [00:01<00:01,  7.46it/s]\u001b[A\n",
            "Eval:  56%|█████▋    | 9/16 [00:01<00:00,  7.49it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 10/16 [00:01<00:00,  6.98it/s]\u001b[A\n",
            "Eval:  69%|██████▉   | 11/16 [00:01<00:00,  7.10it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 12/16 [00:01<00:00,  7.13it/s]\u001b[A\n",
            "Eval:  81%|████████▏ | 13/16 [00:01<00:00,  7.17it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 14/16 [00:02<00:00,  6.74it/s]\u001b[A\n",
            "Eval:  94%|█████████▍| 15/16 [00:02<00:00,  6.96it/s]\u001b[A\n",
            "Epoch 0:  40%|███▉      | 1385/3463 [04:04<31:04,  1.11batch/s, loss=0.0236]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.975 , current loss is 0.06618549255654216 , lowest_valid_loss : 0.06618549255654216\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  60%|█████▉    | 2076/3463 [06:03<03:47,  6.09batch/s, loss=0.0414]\n",
            "Eval:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   6%|▋         | 1/16 [00:00<00:03,  4.41it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 2/16 [00:00<00:02,  5.80it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 3/16 [00:00<00:02,  6.43it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 4/16 [00:00<00:01,  6.82it/s]\u001b[A\n",
            "Eval:  31%|███▏      | 5/16 [00:00<00:01,  7.02it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 6/16 [00:00<00:01,  7.08it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 7/16 [00:01<00:01,  7.29it/s]\u001b[A\n",
            "Eval:  50%|█████     | 8/16 [00:01<00:01,  7.45it/s]\u001b[A\n",
            "Eval:  56%|█████▋    | 9/16 [00:01<00:00,  7.49it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 10/16 [00:01<00:00,  7.00it/s]\u001b[A\n",
            "Eval:  69%|██████▉   | 11/16 [00:01<00:00,  7.06it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 12/16 [00:01<00:00,  7.10it/s]\u001b[A\n",
            "Eval:  81%|████████▏ | 13/16 [00:01<00:00,  7.15it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 14/16 [00:02<00:00,  6.76it/s]\u001b[A\n",
            "Eval:  94%|█████████▍| 15/16 [00:02<00:00,  6.93it/s]\u001b[A\n",
            "Epoch 0:  60%|█████▉    | 2077/3463 [06:05<20:37,  1.12batch/s, loss=0.0414]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.97975 , current loss is 0.06331233226228505 , lowest_valid_loss : 0.06331233226228505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  80%|███████▉  | 2768/3463 [08:03<01:56,  5.95batch/s, loss=0.0468]\n",
            "Eval:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   6%|▋         | 1/16 [00:00<00:03,  4.40it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 2/16 [00:00<00:02,  5.71it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 3/16 [00:00<00:02,  6.33it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 4/16 [00:00<00:01,  6.77it/s]\u001b[A\n",
            "Eval:  31%|███▏      | 5/16 [00:00<00:01,  7.02it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 6/16 [00:00<00:01,  7.11it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 7/16 [00:01<00:01,  7.32it/s]\u001b[A\n",
            "Eval:  50%|█████     | 8/16 [00:01<00:01,  7.46it/s]\u001b[A\n",
            "Eval:  56%|█████▋    | 9/16 [00:01<00:00,  7.48it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 10/16 [00:01<00:00,  6.99it/s]\u001b[A\n",
            "Eval:  69%|██████▉   | 11/16 [00:01<00:00,  7.10it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 12/16 [00:01<00:00,  7.15it/s]\u001b[A\n",
            "Eval:  81%|████████▏ | 13/16 [00:01<00:00,  7.17it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 14/16 [00:02<00:00,  6.78it/s]\u001b[A\n",
            "Eval:  94%|█████████▍| 15/16 [00:02<00:00,  6.95it/s]\u001b[A\n",
            "Epoch 0:  80%|███████▉  | 2769/3463 [08:06<10:24,  1.11batch/s, loss=0.0468]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.979 , current loss is 0.05677792010828853 , lowest_valid_loss : 0.05677792010828853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0: 100%|█████████▉| 3460/3463 [10:04<00:00,  5.21batch/s, loss=0.0339]\n",
            "Eval:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   6%|▋         | 1/16 [00:00<00:03,  4.38it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 2/16 [00:00<00:02,  5.76it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 3/16 [00:00<00:02,  6.43it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 4/16 [00:00<00:01,  6.82it/s]\u001b[A\n",
            "Eval:  31%|███▏      | 5/16 [00:00<00:01,  7.04it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 6/16 [00:00<00:01,  7.15it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 7/16 [00:01<00:01,  7.34it/s]\u001b[A\n",
            "Eval:  50%|█████     | 8/16 [00:01<00:01,  7.47it/s]\u001b[A\n",
            "Eval:  56%|█████▋    | 9/16 [00:01<00:00,  7.52it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 10/16 [00:01<00:00,  7.02it/s]\u001b[A\n",
            "Eval:  69%|██████▉   | 11/16 [00:01<00:00,  7.13it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 12/16 [00:01<00:00,  7.14it/s]\u001b[A\n",
            "Eval:  81%|████████▏ | 13/16 [00:01<00:00,  7.19it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 14/16 [00:02<00:00,  6.81it/s]\u001b[A\n",
            "Eval:  94%|█████████▍| 15/16 [00:02<00:00,  7.01it/s]\u001b[A\n",
            "Epoch 0: 100%|█████████▉| 3461/3463 [10:07<00:01,  1.08batch/s, loss=0.0339]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.9815 , current loss is 0.05391442426480353 , lowest_valid_loss : 0.05391442426480353\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0: 100%|██████████| 3463/3463 [10:07<00:00,  5.70batch/s, loss=0.0894]\n",
            "Epoch 1:  20%|█▉        | 692/3463 [01:59<07:41,  6.01batch/s, loss=0.088] \n",
            "Eval:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   6%|▋         | 1/16 [00:00<00:03,  4.31it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 2/16 [00:00<00:02,  5.62it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 3/16 [00:00<00:02,  6.29it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 4/16 [00:00<00:01,  6.70it/s]\u001b[A\n",
            "Eval:  31%|███▏      | 5/16 [00:00<00:01,  6.89it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 6/16 [00:00<00:01,  7.00it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 7/16 [00:01<00:01,  7.19it/s]\u001b[A\n",
            "Eval:  50%|█████     | 8/16 [00:01<00:01,  7.34it/s]\u001b[A\n",
            "Eval:  56%|█████▋    | 9/16 [00:01<00:00,  7.38it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 10/16 [00:01<00:00,  6.94it/s]\u001b[A\n",
            "Eval:  69%|██████▉   | 11/16 [00:01<00:00,  7.05it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 12/16 [00:01<00:00,  7.10it/s]\u001b[A\n",
            "Eval:  81%|████████▏ | 13/16 [00:01<00:00,  7.15it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 14/16 [00:02<00:00,  6.76it/s]\u001b[A\n",
            "Eval:  94%|█████████▍| 15/16 [00:02<00:00,  6.91it/s]\u001b[A\n",
            "Epoch 1:  20%|██        | 694/3463 [02:01<30:35,  1.51batch/s, loss=0.0362]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lower than previous accuracy, accuracy is :  0.9795 , current loss is 0.05601000983733684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  40%|███▉      | 1384/3463 [03:59<06:18,  5.49batch/s, loss=0.0344]\n",
            "Eval:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   6%|▋         | 1/16 [00:00<00:03,  4.18it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 2/16 [00:00<00:02,  5.65it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 3/16 [00:00<00:02,  6.32it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 4/16 [00:00<00:01,  6.72it/s]\u001b[A\n",
            "Eval:  31%|███▏      | 5/16 [00:00<00:01,  6.94it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 6/16 [00:00<00:01,  7.04it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 7/16 [00:01<00:01,  7.26it/s]\u001b[A\n",
            "Eval:  50%|█████     | 8/16 [00:01<00:01,  7.41it/s]\u001b[A\n",
            "Eval:  56%|█████▋    | 9/16 [00:01<00:00,  7.39it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 10/16 [00:01<00:00,  6.92it/s]\u001b[A\n",
            "Eval:  69%|██████▉   | 11/16 [00:01<00:00,  7.02it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 12/16 [00:01<00:00,  7.08it/s]\u001b[A\n",
            "Eval:  81%|████████▏ | 13/16 [00:01<00:00,  7.12it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 14/16 [00:02<00:00,  6.74it/s]\u001b[A\n",
            "Eval:  94%|█████████▍| 15/16 [00:02<00:00,  6.90it/s]\u001b[A\n",
            "Epoch 1:  40%|████      | 1386/3463 [04:02<23:06,  1.50batch/s, loss=0.0807]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lower than previous accuracy, accuracy is :  0.981 , current loss is 0.055200992501340806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  60%|█████▉    | 2076/3463 [06:00<03:55,  5.90batch/s, loss=0.121] \n",
            "Eval:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   6%|▋         | 1/16 [00:00<00:03,  4.30it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 2/16 [00:00<00:02,  5.70it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 3/16 [00:00<00:02,  6.35it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 4/16 [00:00<00:01,  6.71it/s]\u001b[A\n",
            "Eval:  31%|███▏      | 5/16 [00:00<00:01,  6.91it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 6/16 [00:00<00:01,  7.01it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 7/16 [00:01<00:01,  7.23it/s]\u001b[A\n",
            "Eval:  50%|█████     | 8/16 [00:01<00:01,  7.37it/s]\u001b[A\n",
            "Eval:  56%|█████▋    | 9/16 [00:01<00:00,  7.42it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 10/16 [00:01<00:00,  6.93it/s]\u001b[A\n",
            "Eval:  69%|██████▉   | 11/16 [00:01<00:00,  7.05it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 12/16 [00:01<00:00,  7.10it/s]\u001b[A\n",
            "Eval:  81%|████████▏ | 13/16 [00:01<00:00,  7.13it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 14/16 [00:02<00:00,  6.75it/s]\u001b[A\n",
            "Eval:  94%|█████████▍| 15/16 [00:02<00:00,  6.92it/s]\u001b[A\n",
            "Epoch 1:  60%|██████    | 2078/3463 [06:03<15:16,  1.51batch/s, loss=0.0082]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lower than previous accuracy, accuracy is :  0.9825 , current loss is 0.05419547110795975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  80%|███████▉  | 2768/3463 [08:01<02:00,  5.75batch/s, loss=0.0261]\n",
            "Eval:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   6%|▋         | 1/16 [00:00<00:03,  4.51it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 2/16 [00:00<00:02,  5.82it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 3/16 [00:00<00:02,  6.39it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 4/16 [00:00<00:01,  6.79it/s]\u001b[A\n",
            "Eval:  31%|███▏      | 5/16 [00:00<00:01,  7.00it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 6/16 [00:00<00:01,  7.06it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 7/16 [00:01<00:01,  7.26it/s]\u001b[A\n",
            "Eval:  50%|█████     | 8/16 [00:01<00:01,  7.38it/s]\u001b[A\n",
            "Eval:  56%|█████▋    | 9/16 [00:01<00:00,  7.41it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 10/16 [00:01<00:00,  6.94it/s]\u001b[A\n",
            "Eval:  69%|██████▉   | 11/16 [00:01<00:00,  7.07it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 12/16 [00:01<00:00,  7.13it/s]\u001b[A\n",
            "Eval:  81%|████████▏ | 13/16 [00:01<00:00,  7.18it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 14/16 [00:02<00:00,  6.78it/s]\u001b[A\n",
            "Eval:  94%|█████████▍| 15/16 [00:02<00:00,  6.92it/s]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 2769/3463 [08:04<10:33,  1.10batch/s, loss=0.0261]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.98025 , current loss is 0.05081794655416161 , lowest_valid_loss : 0.05081794655416161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|█████████▉| 3460/3463 [10:02<00:00,  5.68batch/s, loss=0.0523]\n",
            "Eval:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   6%|▋         | 1/16 [00:00<00:03,  4.39it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 2/16 [00:00<00:02,  5.78it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 3/16 [00:00<00:02,  6.37it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 4/16 [00:00<00:01,  6.78it/s]\u001b[A\n",
            "Eval:  31%|███▏      | 5/16 [00:00<00:01,  6.95it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 6/16 [00:00<00:01,  7.04it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 7/16 [00:01<00:01,  7.28it/s]\u001b[A\n",
            "Eval:  50%|█████     | 8/16 [00:01<00:01,  7.43it/s]\u001b[A\n",
            "Eval:  56%|█████▋    | 9/16 [00:01<00:00,  7.48it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 10/16 [00:01<00:00,  7.00it/s]\u001b[A\n",
            "Eval:  69%|██████▉   | 11/16 [00:01<00:00,  7.11it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 12/16 [00:01<00:00,  7.15it/s]\u001b[A\n",
            "Eval:  81%|████████▏ | 13/16 [00:01<00:00,  7.16it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 14/16 [00:02<00:00,  6.75it/s]\u001b[A\n",
            "Eval:  94%|█████████▍| 15/16 [00:02<00:00,  6.91it/s]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 3461/3463 [10:05<00:01,  1.10batch/s, loss=0.0523]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.9825 , current loss is 0.04942343931179494 , lowest_valid_loss : 0.04942343931179494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 3463/3463 [10:05<00:00,  5.72batch/s, loss=0.0558]\n",
            "Epoch 2:  20%|█▉        | 692/3463 [01:58<07:48,  5.91batch/s, loss=0.0154]\n",
            "Eval:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   6%|▋         | 1/16 [00:00<00:03,  4.24it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 2/16 [00:00<00:02,  5.64it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 3/16 [00:00<00:02,  6.28it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 4/16 [00:00<00:01,  6.75it/s]\u001b[A\n",
            "Eval:  31%|███▏      | 5/16 [00:00<00:01,  7.00it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 6/16 [00:00<00:01,  7.08it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 7/16 [00:01<00:01,  7.28it/s]\u001b[A\n",
            "Eval:  50%|█████     | 8/16 [00:01<00:01,  7.40it/s]\u001b[A\n",
            "Eval:  56%|█████▋    | 9/16 [00:01<00:00,  7.44it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 10/16 [00:01<00:00,  6.97it/s]\u001b[A\n",
            "Eval:  69%|██████▉   | 11/16 [00:01<00:00,  7.06it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 12/16 [00:01<00:00,  7.09it/s]\u001b[A\n",
            "Eval:  81%|████████▏ | 13/16 [00:01<00:00,  7.12it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 14/16 [00:02<00:00,  6.73it/s]\u001b[A\n",
            "Eval:  94%|█████████▍| 15/16 [00:02<00:00,  6.91it/s]\u001b[A\n",
            "Epoch 2:  20%|██        | 694/3463 [02:01<30:42,  1.50batch/s, loss=0.111]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lower than previous accuracy, accuracy is :  0.9825 , current loss is 0.05029514350462705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  40%|███▉      | 1384/3463 [03:59<05:55,  5.85batch/s, loss=0.0317]\n",
            "Eval:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   6%|▋         | 1/16 [00:00<00:03,  4.32it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 2/16 [00:00<00:02,  5.70it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 3/16 [00:00<00:02,  6.33it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 4/16 [00:00<00:01,  6.70it/s]\u001b[A\n",
            "Eval:  31%|███▏      | 5/16 [00:00<00:01,  6.92it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 6/16 [00:00<00:01,  7.01it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 7/16 [00:01<00:01,  7.22it/s]\u001b[A\n",
            "Eval:  50%|█████     | 8/16 [00:01<00:01,  7.33it/s]\u001b[A\n",
            "Eval:  56%|█████▋    | 9/16 [00:01<00:00,  7.35it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 10/16 [00:01<00:00,  6.91it/s]\u001b[A\n",
            "Eval:  69%|██████▉   | 11/16 [00:01<00:00,  7.05it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 12/16 [00:01<00:00,  7.10it/s]\u001b[A\n",
            "Eval:  81%|████████▏ | 13/16 [00:01<00:00,  7.16it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 14/16 [00:02<00:00,  6.76it/s]\u001b[A\n",
            "Eval:  94%|█████████▍| 15/16 [00:02<00:00,  6.90it/s]\u001b[A\n",
            "Epoch 2:  40%|████      | 1386/3463 [04:01<22:46,  1.52batch/s, loss=0.0164]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lower than previous accuracy, accuracy is :  0.98275 , current loss is 0.05027228296967223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  60%|█████▉    | 2076/3463 [06:00<03:58,  5.82batch/s, loss=0.0135]\n",
            "Eval:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   6%|▋         | 1/16 [00:00<00:03,  4.45it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 2/16 [00:00<00:02,  5.81it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 3/16 [00:00<00:02,  6.42it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 4/16 [00:00<00:01,  6.82it/s]\u001b[A\n",
            "Eval:  31%|███▏      | 5/16 [00:00<00:01,  7.01it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 6/16 [00:00<00:01,  7.06it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 7/16 [00:01<00:01,  7.24it/s]\u001b[A\n",
            "Eval:  50%|█████     | 8/16 [00:01<00:01,  7.38it/s]\u001b[A\n",
            "Eval:  56%|█████▋    | 9/16 [00:01<00:00,  7.43it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 10/16 [00:01<00:00,  6.95it/s]\u001b[A\n",
            "Eval:  69%|██████▉   | 11/16 [00:01<00:00,  7.07it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 12/16 [00:01<00:00,  7.13it/s]\u001b[A\n",
            "Eval:  81%|████████▏ | 13/16 [00:01<00:00,  7.19it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 14/16 [00:02<00:00,  6.81it/s]\u001b[A\n",
            "Eval:  94%|█████████▍| 15/16 [00:02<00:00,  6.97it/s]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 2077/3463 [06:03<21:08,  1.09batch/s, loss=0.0135]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.98425 , current loss is 0.04820158542133868 , lowest_valid_loss : 0.04820158542133868\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  80%|███████▉  | 2768/3463 [08:02<02:01,  5.70batch/s, loss=0.0135]\n",
            "Eval:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   6%|▋         | 1/16 [00:00<00:03,  4.41it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 2/16 [00:00<00:02,  5.83it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 3/16 [00:00<00:02,  6.33it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 4/16 [00:00<00:01,  6.76it/s]\u001b[A\n",
            "Eval:  31%|███▏      | 5/16 [00:00<00:01,  6.99it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 6/16 [00:00<00:01,  7.07it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 7/16 [00:01<00:01,  7.28it/s]\u001b[A\n",
            "Eval:  50%|█████     | 8/16 [00:01<00:01,  7.43it/s]\u001b[A\n",
            "Eval:  56%|█████▋    | 9/16 [00:01<00:00,  7.46it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 10/16 [00:01<00:00,  6.98it/s]\u001b[A\n",
            "Eval:  69%|██████▉   | 11/16 [00:01<00:00,  7.11it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 12/16 [00:01<00:00,  7.16it/s]\u001b[A\n",
            "Eval:  81%|████████▏ | 13/16 [00:01<00:00,  7.20it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 14/16 [00:02<00:00,  6.80it/s]\u001b[A\n",
            "Eval:  94%|█████████▍| 15/16 [00:02<00:00,  6.98it/s]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 2770/3463 [08:04<07:38,  1.51batch/s, loss=0.0217]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lower than previous accuracy, accuracy is :  0.9775 , current loss is 0.05639026407152414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|█████████▉| 3460/3463 [10:02<00:00,  5.64batch/s, loss=0.0331]\n",
            "Eval:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   6%|▋         | 1/16 [00:00<00:03,  4.31it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 2/16 [00:00<00:02,  5.70it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 3/16 [00:00<00:02,  6.31it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 4/16 [00:00<00:01,  6.75it/s]\u001b[A\n",
            "Eval:  31%|███▏      | 5/16 [00:00<00:01,  6.96it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 6/16 [00:00<00:01,  7.07it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 7/16 [00:01<00:01,  7.24it/s]\u001b[A\n",
            "Eval:  50%|█████     | 8/16 [00:01<00:01,  7.38it/s]\u001b[A\n",
            "Eval:  56%|█████▋    | 9/16 [00:01<00:00,  7.43it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 10/16 [00:01<00:00,  6.95it/s]\u001b[A\n",
            "Eval:  69%|██████▉   | 11/16 [00:01<00:00,  7.07it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 12/16 [00:01<00:00,  7.13it/s]\u001b[A\n",
            "Eval:  81%|████████▏ | 13/16 [00:01<00:00,  7.16it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 14/16 [00:02<00:00,  6.77it/s]\u001b[A\n",
            "Eval:  94%|█████████▍| 15/16 [00:02<00:00,  6.94it/s]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 3462/3463 [10:05<00:00,  1.50batch/s, loss=0.0258]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lower than previous accuracy, accuracy is :  0.9825 , current loss is 0.048425897082779557\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 3463/3463 [10:05<00:00,  5.72batch/s, loss=0.0606]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1fe327b0fe74445b42a3a177e1125ec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▃▅▅▆▅▆▇▆▇▇▇█▄▇</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid_loss</td><td>█▅▄▃▂▃▂▂▂▁▁▁▁▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.9825</td></tr><tr><td>learning_rate</td><td>1e-05</td></tr><tr><td>valid_loss</td><td>0.04843</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">visionary-galaxy-8</strong>: <a href=\"https://wandb.ai/jinseonggram/uncategorized/runs/1qx3bvrc\" target=\"_blank\">https://wandb.ai/jinseonggram/uncategorized/runs/1qx3bvrc</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20221002_215408-1qx3bvrc/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "train_epoch = 3\n",
        "lowest_valid_loss = 9999.\n",
        "\n",
        "#scheduler\n",
        "# scheduler = optim.lr_scheduler.LambdaLR(optimizer=optimizer, lr_lambda=lambda epoch: 0.5 ** (epoch+5))\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.5)\n",
        "\n",
        "# early stopping\n",
        "patience_limit = 2\n",
        "patience_check = 0\n",
        "\n",
        "wandb.init()\n",
        "wandb.run.name = 'albert_adding_scheduler'\n",
        "\n",
        "\n",
        "for epoch in range(train_epoch):\n",
        "\n",
        "    # tqdm 은 Bar 형태로 학습량을 알려주는 module.\n",
        "    with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
        "\n",
        "\n",
        "        for iteration, (input_ids, attention_mask, token_type_ids, position_ids, labels) in enumerate(tepoch):\n",
        "            tepoch.set_description(f\"Epoch {epoch}\")\n",
        "\n",
        "            # 모든 데이터를 GPU 로 옮겨줌.\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            token_type_ids = token_type_ids.to(device)\n",
        "            position_ids = position_ids.to(device)\n",
        "            labels = labels.to(device, dtype=torch.long)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward-propagation 연산 진행\n",
        "            output = model(input_ids=input_ids,\n",
        "                           attention_mask=attention_mask,\n",
        "                           token_type_ids=token_type_ids,\n",
        "                           position_ids=position_ids,\n",
        "                           labels=labels)\n",
        "\n",
        "            loss = output.loss\n",
        "\n",
        "            # back-propagation 연산\n",
        "            loss.backward()\n",
        "\n",
        "            # 가중치 update\n",
        "            optimizer.step()  \n",
        "\n",
        "            # tqdm 에서 loss 를 출력하기 위해 loss 를 넣어줌.\n",
        "            tepoch.set_postfix(loss=loss.item())\n",
        "\n",
        "\n",
        "            # int(len(train_loader) / 5) == 0 마다 validation set 으로 evaluate.\n",
        "            if iteration != 0 and iteration % int(len(train_loader) / 5) == 0:\n",
        "                # Evaluate the model five times per epoch\n",
        "                with torch.no_grad():\n",
        "                    model.eval()\n",
        "                    valid_losses = []\n",
        "                    predictions = []\n",
        "                    target_labels = []\n",
        "                    for input_ids, attention_mask, token_type_ids, position_ids, labels in tqdm(dev_loader,\n",
        "                                                                                                desc='Eval',\n",
        "                                                                                                position=1,\n",
        "                                                                                                leave=None):\n",
        "                        input_ids = input_ids.to(device)\n",
        "                        attention_mask = attention_mask.to(device)\n",
        "                        token_type_ids = token_type_ids.to(device)\n",
        "                        position_ids = position_ids.to(device)\n",
        "                        labels = labels.to(device, dtype=torch.long)\n",
        "\n",
        "                        output = model(input_ids=input_ids,\n",
        "                                       attention_mask=attention_mask,\n",
        "                                       token_type_ids=token_type_ids,\n",
        "                                       position_ids=position_ids,\n",
        "                                       labels=labels)\n",
        "\n",
        "                        # logits : tensor([[ 2.0392, -1.4302], [-1.1802,  2.7419], ...])\n",
        "                        logits = output.logits\n",
        "\n",
        "                        # loss :  tensor(0.1518, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
        "                        loss = output.loss\n",
        "                        valid_losses.append(loss.item())\n",
        "\n",
        "                        batch_predictions = [0 if example[0] > example[1] else 1 for example in logits]\n",
        "                        batch_labels = [int(example) for example in labels]\n",
        "\n",
        "                        predictions += batch_predictions\n",
        "                        target_labels += batch_labels\n",
        "\n",
        "\n",
        "                # valid_losses : [0.07377569377422333, 0.0990561693906784, ..., 0.02395477145910263], len == 16\n",
        "                # predictions :  [0, 0, 0, ..., 0] , len == 4000\n",
        "                # target_labels : [1, 1, 1, ..., 0] , len == 4000\n",
        "                # np.array(predictions) == np.array(target_labels) : [ True ...  True  True  True]\n",
        "                # (np.array(predictions) == np.array(target_labels)).mean() : 0.9705\n",
        "\n",
        "                acc = compute_acc(predictions, target_labels)\n",
        "                valid_loss = sum(valid_losses) / len(valid_losses)\n",
        "                if lowest_valid_loss > valid_loss:\n",
        "                    lowest_valid_loss = valid_loss\n",
        "                    print('Acc for model which have lower valid loss: ', acc, ', current loss is', valid_loss, ', lowest_valid_loss :', lowest_valid_loss)\n",
        "                    torch.save(model.state_dict(), \"./pytorch_model.bin\")\n",
        "\n",
        "                # early stopping 코드 추가\n",
        "                    patience_check = 0\n",
        "                else:\n",
        "                    print('Lower than previous accuracy, accuracy is : ', acc, ', current loss is', valid_loss)\n",
        "                    patience_limit += 1\n",
        "                    if patience_check >= patience_limit: # early stopping 조건 만족 시 조기 종료\n",
        "                        print('Ended training for bigger patience_check than limit')\n",
        "                        break\n",
        "\n",
        "                wandb.log({\"accuracy\":acc, \"valid_loss\":valid_loss, \"learning_rate\":learning_rate})    \n",
        "    # scheduler\n",
        "    scheduler.step()\n",
        "wandb.finish()   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "P95gtlnurvgX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "test_df = pd.read_csv('test_no_label.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "cLDzC10ErvgX"
      },
      "outputs": [],
      "source": [
        "test_dataset = test_df['Id']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "jnt693N0rvgX"
      },
      "outputs": [],
      "source": [
        "def make_id_file_test(tokenizer, test_dataset):\n",
        "    data_strings = []\n",
        "    id_file_data = [tokenizer.encode(sent.lower()) for sent in test_dataset]\n",
        "    for item in id_file_data:\n",
        "        data_strings.append(' '.join([str(k) for k in item]))\n",
        "    return data_strings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "7C5PpXtlrvgY"
      },
      "outputs": [],
      "source": [
        "test = make_id_file_test(tokenizer, test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aqse7SHrvgY",
        "outputId": "232e29a7-8d4a-421f-999a-bdf755201977"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['2 32 13 22 18 21 979 78 1496 17 78 11974 18 206 85 42 162 13 9 3',\n",
              " '2 86 17841 37 40 315 3839 13 9 3',\n",
              " '2 32 25 14 127 14351 7804 19 14 1152 13 9 3',\n",
              " '2 107 52 1676 21 9140 29 158 148 13 9 3',\n",
              " '2 31 23 4741 17 39 117 55 583 86 5733 17 5575 13 9 3',\n",
              " '2 14 104 584 95 420 30 23 1047 23 14 2364 13 9 3',\n",
              " '2 90 13 15 52 14 53 18 35 28 291 13 15 14 53 18 19 1630 183 13 9 3',\n",
              " '2 59 1499 32 70 431 26 42 17 50 253 15600 13 9 3',\n",
              " '2 3123 14 13533 144 13 103 22 38 166 143 184 20 170 14 1428 13 9 3',\n",
              " '2 59 57 40 5977 3155 16 22621 18 20 3538 37 13 9 3']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "test[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "cZi14gnnrvgY"
      },
      "outputs": [],
      "source": [
        "class SentimentTestDataset(object):\n",
        "    def __init__(self, tokenizer, test):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = []\n",
        "\n",
        "        for sent in test:\n",
        "            self.data += [self._cast_to_int(sent.strip().split())]\n",
        "\n",
        "    def _cast_to_int(self, sample):\n",
        "        return [int(word_id) for word_id in sample]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sample = self.data[index]\n",
        "        return np.array(sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "erHjGE9rrvgY"
      },
      "outputs": [],
      "source": [
        "test_dataset = SentimentTestDataset(tokenizer, test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "y03-nDX9rvgZ"
      },
      "outputs": [],
      "source": [
        "def collate_fn_style_test(samples):\n",
        "    input_ids = samples\n",
        "    max_len = max(len(input_id) for input_id in input_ids)\n",
        "\n",
        "    # 버그.\n",
        "    # smaples 가 input id 만 가지고 있음. trainset 은 input_ids 와 labels 둘 다 가졌음. test_dataset 은 labels 이 없음.\n",
        "    # input 의 순서를 바꿔주면 kaggle 에 내가 모르는 labels set 과 순서가 얻 바뀌게 된다.\n",
        "    # sorted_indices = np.argsort([len(input_id) for input_id in input_ids])[::-1]\n",
        "    sorted_indices = range(len(input_ids))\n",
        "\n",
        "    input_ids = pad_sequence([torch.tensor(input_ids[index]) for index in sorted_indices],\n",
        "                             batch_first=True)\n",
        "    # attention_mask = torch.tensor(\n",
        "    #     [[1] * len(input_ids[index]) + [0] * (max_len - len(input_ids[index])) for index in\n",
        "    #      sorted_indices])\n",
        "\n",
        "    attention_mask = []\n",
        "    for seq in input_ids:\n",
        "        seq_mask = [float(i>0) for i in seq]\n",
        "        attention_mask.append(seq_mask)\n",
        "    attention_mask = torch.tensor(attention_mask)\n",
        "\n",
        "    token_type_ids = torch.tensor([[0] * len(input_ids[index]) for index in sorted_indices])\n",
        "    position_ids = torch.tensor([list(range(len(input_ids[index]))) for index in sorted_indices])\n",
        "\n",
        "    return input_ids, attention_mask, token_type_ids, position_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "gZ0l1HparvgZ"
      },
      "outputs": [],
      "source": [
        "test_batch_size = 32\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size,\n",
        "                                          shuffle=False, collate_fn=collate_fn_style_test,\n",
        "                                          num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoSHTbJUrvgZ",
        "outputId": "bed97fa4-acee-45bd-9210-c39250a9b3c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Test:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Test:   3%|▎         | 1/32 [00:00<00:04,  7.52it/s]\u001b[A\n",
            "Test:  19%|█▉        | 6/32 [00:00<00:00, 27.13it/s]\u001b[A\n",
            "Test:  34%|███▍      | 11/32 [00:00<00:00, 35.06it/s]\u001b[A\n",
            "Test:  50%|█████     | 16/32 [00:00<00:00, 38.33it/s]\u001b[A\n",
            "Test:  66%|██████▌   | 21/32 [00:00<00:00, 40.05it/s]\u001b[A\n",
            "Test:  81%|████████▏ | 26/32 [00:00<00:00, 40.82it/s]\u001b[A\n",
            "Test:  97%|█████████▋| 31/32 [00:00<00:00, 42.80it/s]\u001b[A\n",
            "                                                     \u001b[A"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    for input_ids, attention_mask, token_type_ids, position_ids in tqdm(test_loader,\n",
        "                                                                        desc='Test',\n",
        "                                                                        position=1,\n",
        "                                                                        leave=None):\n",
        "\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "        token_type_ids = token_type_ids.to(device)\n",
        "        position_ids = position_ids.to(device)\n",
        "\n",
        "        output = model(input_ids=input_ids,\n",
        "                       attention_mask=attention_mask,\n",
        "                       token_type_ids=token_type_ids,\n",
        "                       position_ids=position_ids)\n",
        "\n",
        "        logits = output.logits\n",
        "        batch_predictions = [0 if example[0] > example[1] else 1 for example in logits]\n",
        "        predictions += batch_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "tGO3aS-VrvgZ"
      },
      "outputs": [],
      "source": [
        "test_df['Category'] = predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "VndXxal3rvgZ"
      },
      "outputs": [],
      "source": [
        "test_df.to_csv('submission_albert_scheduler.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOKGZyyAGcxx"
      },
      "source": [
        "# 새 섹션"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "62f2348e08eb40aeba7d33b66baf1ff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8738b98f152142d2a177f4ee50d8a6ff",
              "IPY_MODEL_9548480e42904ff4832484dffe062d40",
              "IPY_MODEL_762b596999174feaa588963c0345da90"
            ],
            "layout": "IPY_MODEL_197e3e9cebfd40639c05e3afdc6e5a4c"
          }
        },
        "8738b98f152142d2a177f4ee50d8a6ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42e37e5d79f24e98a0465166d5a9ba0b",
            "placeholder": "​",
            "style": "IPY_MODEL_4a01a2b91b104f4ea0da7627e8165955",
            "value": "Downloading: 100%"
          }
        },
        "9548480e42904ff4832484dffe062d40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_faf7049c768541bbaf1a89ad61b58bf7",
            "max": 760289,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e517071f6eb1419fab44023518f478ab",
            "value": 760289
          }
        },
        "762b596999174feaa588963c0345da90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3183323db2e94e54b3f5763280bd2257",
            "placeholder": "​",
            "style": "IPY_MODEL_18362cfce3a74dbcbe427f336ed5c378",
            "value": " 760k/760k [00:00&lt;00:00, 583kB/s]"
          }
        },
        "197e3e9cebfd40639c05e3afdc6e5a4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42e37e5d79f24e98a0465166d5a9ba0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a01a2b91b104f4ea0da7627e8165955": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "faf7049c768541bbaf1a89ad61b58bf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e517071f6eb1419fab44023518f478ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3183323db2e94e54b3f5763280bd2257": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18362cfce3a74dbcbe427f336ed5c378": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67360c7aaa1e4eb99aeaf0c58dfdc56f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ae0b4eb347524a22976c56554cf17678",
              "IPY_MODEL_2be4709a0fe9473f847b18d762e1a7e8",
              "IPY_MODEL_a36e90ac65ad437885ee984cb5f23865"
            ],
            "layout": "IPY_MODEL_0caff7507416409d9d19a755e4b8fcf2"
          }
        },
        "ae0b4eb347524a22976c56554cf17678": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0dd3a19a30848c2a2e983227ab38f05",
            "placeholder": "​",
            "style": "IPY_MODEL_5ac57ca70c114341b5f4fb4a6b81055b",
            "value": "Downloading: 100%"
          }
        },
        "2be4709a0fe9473f847b18d762e1a7e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c17295c1c46481795d9eace888f4d38",
            "max": 684,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20c233796c16462caa5a2069adb0deda",
            "value": 684
          }
        },
        "a36e90ac65ad437885ee984cb5f23865": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b1600090f544a8e9ff64620215f3421",
            "placeholder": "​",
            "style": "IPY_MODEL_de35c7639d474eafb793f6476d260b34",
            "value": " 684/684 [00:00&lt;00:00, 27.9kB/s]"
          }
        },
        "0caff7507416409d9d19a755e4b8fcf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0dd3a19a30848c2a2e983227ab38f05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ac57ca70c114341b5f4fb4a6b81055b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c17295c1c46481795d9eace888f4d38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20c233796c16462caa5a2069adb0deda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b1600090f544a8e9ff64620215f3421": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de35c7639d474eafb793f6476d260b34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb7a330500aa4abdbda219867697f11a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e06884a6b354150bf8d1dfd5b9ba87c",
              "IPY_MODEL_6ce242e334cb414f88738a527fb49bae",
              "IPY_MODEL_32127cf0faf845d2bb2a54dd988f2185"
            ],
            "layout": "IPY_MODEL_345d45ea8c574103a16e8a3c2d4d367a"
          }
        },
        "3e06884a6b354150bf8d1dfd5b9ba87c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de2f19d81061499a9563857db295f25f",
            "placeholder": "​",
            "style": "IPY_MODEL_ddd8903a26004259a780f6dbce0fa78b",
            "value": "Downloading: 100%"
          }
        },
        "6ce242e334cb414f88738a527fb49bae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b66dae20e8c40e496c3824818a5ef32",
            "max": 47376696,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4712e13e380346e3ace5d7feb7e76e85",
            "value": 47376696
          }
        },
        "32127cf0faf845d2bb2a54dd988f2185": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fb5222330304651940f693b516c5b02",
            "placeholder": "​",
            "style": "IPY_MODEL_0bd153b0b8bb46f0ba4968d3ad8afd59",
            "value": " 47.4M/47.4M [00:00&lt;00:00, 59.7MB/s]"
          }
        },
        "345d45ea8c574103a16e8a3c2d4d367a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de2f19d81061499a9563857db295f25f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddd8903a26004259a780f6dbce0fa78b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b66dae20e8c40e496c3824818a5ef32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4712e13e380346e3ace5d7feb7e76e85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0fb5222330304651940f693b516c5b02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bd153b0b8bb46f0ba4968d3ad8afd59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1fe327b0fe74445b42a3a177e1125ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd336e7c9c2748a1a86f06d99bc24bd4",
              "IPY_MODEL_0fbaeef907ee4c2c953fdf4f59f03df1"
            ],
            "layout": "IPY_MODEL_79b20f1c45a04c2194b1565aac065151"
          }
        },
        "bd336e7c9c2748a1a86f06d99bc24bd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9485e1d43274d4581dcbfd30e081be6",
            "placeholder": "​",
            "style": "IPY_MODEL_1b5302f2a5834ce39cd1ed901e517fc7",
            "value": "0.011 MB of 0.011 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "0fbaeef907ee4c2c953fdf4f59f03df1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d81c88bab31e438da5362cc780924b6d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_401fab58599a46a3bffac5fa2b0c0aa5",
            "value": 1
          }
        },
        "79b20f1c45a04c2194b1565aac065151": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9485e1d43274d4581dcbfd30e081be6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b5302f2a5834ce39cd1ed901e517fc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d81c88bab31e438da5362cc780924b6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "401fab58599a46a3bffac5fa2b0c0aa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}